---
layout : single
title : "2022-03-18-혼공머신_KNN(feat.Data Scaling)" 
---

### 2 | 데이터 전처리

#### 데이터 세트 만들기 (feat. numpy)



```python
# 길이
fish_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0, 9.8, 
                10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]

# 무게
fish_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0, 6.7, 
                7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]


import numpy as np

np.column_stack((fish_length,fish_weight))
# stack : 튜플의 원소를 하나씩 꺼내서 대응시켜줌

fish_target = np.concatenate((np.ones(35),np.zeros(14))) # 얘도 튜플 써야 함
```

#### 훈련세트와 테스트세트 나누기 (feat.사이킷런)

##### train_test_split : 알잘딱깔센

```python
from sklearn.model_selection import train_test_split

train_input,test_input,train_target,test_target = train_test_split(fish_data, fish_target, random_state = 42, stratify = fish_target )
# random_state로 시드 지정 가능
# starify로 클래스 비율 지정 가능(편향 방지)
```

제대로 됐나 보자.


```python

from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier()

kn.fit(train_input,train_target)

print(kn.score(test_input, test_target))

```

저번에 여기까지 했는데 데이콘 덕에 왠지 오랜만에 하는 느낌이다.

```python
print(kn.predict([[25,150]]))
```

0이래는데...?  

왠지 찾아보자.

```python
train_input = input_arr[index[:35]]

train_target = target_arr[index[:35]]

test_input = input_arr[index[35:]]

test_target = target_arr[index[35:]]

import matplotlib.pyplot as plt

plt.scatter(train_input[:,0],train_input[:,1],label = 'train')
plt.scatter(25,150,marker='^')

plt.legend()
plt.xlabel('length')
plt.ylabel('weight')

plt.show()
```

아 스케일링이 안돼있으니까 객관적으로 보이지가 않는거였다.  

찐거리를 한 번 봐보자.

```python
distances, indexes = kn.kneighbors([[25,150]])

plt.scatter(train_input[:,0],train_input[:,1],label = 'train')
plt.scatter(25,150,marker='^')
plt.scatter(train_input[indexes,0], train_input[indexes,1],marker = 'D')

plt.legend()
plt.xlabel('length')
plt.ylabel('weight')

plt.show()

print(train_input[indexes])

print(distances)
```

x, y축의 눈금을 같이 해보자.

```python
plt.scatter(train_input[:,0],train_input[:,1],label = 'train')
plt.scatter(25,150,marker='^')
plt.scatter(train_input[indexes,0], train_input[indexes,1],marker = 'D')
plt.xlim((0,1000))

plt.legend()
plt.xlabel('length')
plt.ylabel('weight')

plt.show()
```

ㅋㅋㅋㅋㅋ거의 뭐 일차함수

이럴 때 **스케일링(Scaling)**이 필요한거임  

방법에는 여러 가지가 있는데  

* 표준화 : 고딩 때 배우는 그 '표준화' 맞음!
* MinMax : (x- min) / (max - min)

```python
# 평균과 표준편차 구하기 
mean = np.mean(train_input, axis = 0)
std = np.std(train_input, axis = 0)

# 표준화
train_scaled = (train_input - mean) / std
```

그럼 이제 어떻게 되는지 보자.

```python
plt.scatter(train_scaled[:,0],train_scaled[:,1],label = 'train')
plt.scatter(new[0],new[1],marker='^')

plt.legend()
plt.xlabel('length')
plt.ylabel('weight')

plt.show()
```

이제 제대로 돌아가는구만.  
이제 전처리된 애로 모델을 훈련시켜보자.

```python
kn.fit(train_scaled,train_target)

test_scaled = (test_input - mean) / std

kn.score(test_scaled,test_target)

print(kn.predict([new]))
```

이번에는 제대로 나온다 다행다행..
