---
layout : single
title : "2022-03-20-혼공머신_KNN(feat.Ridge & Lasso)" 
categories : 
  -selfml
---

### 3 | 특성 공학과 규제

#### 특성 공학 : 기존의 특성을 사용하여 새로운 특성을 추출해내는 작업

사이킷런의 PolynomialFeatures 클래스를 사용할 수 있다.  

먼저 파일을 불러오겠다.  
파일은 [혼공머신 데이터] - (https://bit.ly/perch_csv_data)에서 불러오겠다.

```python
import pandas as pd

df = pd.read_csv('https://bit.ly/perch_csv_data')

perch_full = df.to_numpy

print(perch_full)
```

타겟 데이터도 만들자.

```python
import numpy as np
perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,
       1000.0])
```

테스트 세트와 훈련세트를 만들자.

```python
from sklearn.model_selection import train_test_split
train_input, test_input,train_target, test_target = train_test_split(
    perch_full, perch_weight,random_state = 42
)
```

몇 차의 모델을 만들어야 하는지 보자.

```python
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(include_bias = False )
poly.fit(train_input)
train_poly = poly.transform(train_input)
print(train_poly.shape)

test_poly = poly.transform(test_input)
```

회귀직선을 만들고 평가해보겠다.

```python
from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(train_poly,train_target)

print(lr.score(train_poly,train_target))
print(lr.score(test_poly,test_target))
```

과소 적합 문제는 해결 됐는데 테스트 세트의 정확도가 훈련세트의 정확도보다는 낮다.  
그렇다고 특성을 늘리면 과대적합 오져버린다.(다 해보고 하는 소리)  

****

저번 시간에 여기까지 했다.

#### 규제

훈련세트를 너무 과도하게 학습하지 못하도록 훼방하는 것  

-> 특성에 곱해지는 계수의 크기를 작게 만드는 일
1. 릿지
2. 라쏘

##### 릿지

```python
from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
ss.fit(train_poly)
train_scaled = ss.transform(train_poly)
test_scaled = ss.transform(test_poly)
```

릿지 모형을 만들자.

```python
from sklearn.linear_model import Ridge
ridge = Ridge()
ridge.fit(train_scaled,train_target)
print(ridge.score(train_scaled, train_target))
print(ridge.score(test_scaled, test_target))
```

규제 정도에 따라서 릿지 모형을 만들어보자.

```python
import matplotlib.pyplot as plt
train_score = []
test_score = []

alpha_list = [0.001,0.01,0.1,1,10,100]

for alpha in alpha_list : 
  ridge = Ridge(alpha = alpha)

  ridge.fit(train_scaled, train_target)

  train_score.append(ridge.score(train_scaled, train_target))
  test_score.append(ridge.score(test_scaled, test_target))

print(train_score)
print(test_score)
```
그래프를 통해서 적절한 규제 정도를 찾아보자.

```python
plt.plot(np.log10(alpha_list),train_score,label = 'train')
plt.plot(np.log10(alpha_list),test_score,label = 'test')

plt.xlabel('alpha')
plt.ylabel('R^2')

plt.legend()
plt.show()
```

0.1 ~ 1 사이의 alpha가 과소적합도, 과대적합도 아닌 적절한 규제 정도이다.  
따라서 0.1을 채택하겠다.

```python
ridge = Ridge(alpha = 0.1)
ridge.fit(train_scaled, train_target)
print(ridge.score(train_scaled, train_target))
print(ridge.score(test_scaled, test_target))
```

##### 라쏘

```python
import matplotlib.pyplot as plt
train_score = []
test_score = []

alpha_list = [0.001,0.01,0.1,1,10,100]

for alpha in alpha_list : 
  lasso = Lasso(alpha = alpha, max_iter = 10000)
  lasso.fit(train_scaled, train_target)

  train_score.append(lasso.score(train_scaled, train_target))
  test_score.append(lasso.score(test_scaled, test_target))

plt.plot(np.log10(alpha_list),train_score,label = 'train')
plt.plot(np.log10(alpha_list),test_score,label = 'test')

plt.xlabel('alpha')
plt.ylabel('R^2')

plt.legend()
plt.show()
```
얘는 1이 제일 괜찮은 것 같다.

```python
lasso = Lasso(alpha = 0.1)
lasso.fit(train_scaled, train_target)
print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
```
