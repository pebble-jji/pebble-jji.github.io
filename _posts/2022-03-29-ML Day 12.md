---
layout : single
title : "3/29(화) ML day 12" 
---

## Module Import

```python
import numpy as np

import pandas as pd 

import matplotlib.pyplot as plt

import plotly.express as px

import csv
```

## Data Load

```python
train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.zip (Unzipped Files)/data/train.csv')

train = train.drop('id', axis = 1)

test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.zip (Unzipped Files)/data/test.csv')

test = test.drop('id', axis = 1)
```

### train : 학습 데이터  

* id : 샘플 아이디  

* Gender : 전복 성별  

* Lenght : 전복 길이  

* Diameter : 전복 둘레  

* Height : 전복 키   

* Whole : Weight : 전복 전체 무게  

* Shucked Weight : 껍질을 제외한 무게  

* Viscra Weight : 내장 무게  

* Shell Weight : 껍질 무게  

* Target : 전복 나이

  

### 기본 데이터 조회

```python
train.describe()
```

|       |   Lenght    |  Diameter   |   Height    | Whole Weight | Shucked Weight | Viscra Weight | Shell Weight |   Target    |
| :---: | :---------: | :---------: | :---------: | :----------: | :------------: | :-----------: | :----------: | :---------: |
| count | 1253.000000 | 1253.000000 | 1253.000000 | 1253.000000  |  1253.000000   |  1253.000000  | 1253.000000  | 1253.000000 |
| mean  |  0.522869   |  0.406963   |  0.139545   |   0.831199   |    0.358818    |   0.181006    |   0.240077   |  9.912211   |
|  std  |  0.120231   |  0.099771   |  0.039033   |   0.500491   |    0.224612    |   0.111936    |   0.142574   |  3.214676   |
|  min  |  0.110000   |  0.090000   |  0.030000   |   0.008000   |    0.002500    |   0.002000    |   0.003000   |  3.000000   |
|  25%  |  0.445000   |  0.345000   |  0.115000   |   0.440500   |    0.182500    |   0.092500    |   0.130000   |  8.000000   |
|  50%  |  0.535000   |  0.420000   |  0.140000   |   0.777500   |    0.326000    |   0.168000    |   0.230000   |  10.000000  |
|  75%  |  0.615000   |  0.480000   |  0.165000   |   1.160000   |    0.505500    |   0.256500    |   0.330000   |  11.000000  |
|  max  |  0.780000   |  0.630000   |  0.250000   |   2.779500   |    1.488000    |   0.760000    |   1.005000   |  29.000000  |

```python
train.info()
```

```python
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1253 entries, 0 to 1252 
Data columns (total 9 columns):
 #   Column          Non-Null Count  Dtype   
---  ------          --------------  -----   
0   Gender          1253 non-null   object
1   Lenght          1253 non-null   float64
2   Diameter        1253 non-null   float64
3   Height          1253 non-null   float64
4   Whole Weight    1253 non-null   float64
5   Shucked Weight  1253 non-null   float64
6   Viscra Weight   1253 non-null   float64
7   Shell Weight    1253 non-null   float64
8   Target          1253 non-null   int64   
dtypes: float64(7), int64(1), object(1)
memory usage: 88.2+ KB
```

### 결측치 유무 확인

```python
train.isnull().sum()
```

```python
Gender            0
Lenght            0
Diameter          0
Height            0
Whole Weight      0
Shucked Weight    0
Viscra Weight     0
Shell Weight      0
Target            0
dtype: int64
```

결측치가 없는 것을 볼 수 있다.

### 이상치 확인

```python
feature = train.columns

plt.figure(figsize=(20,30))

for i in range(1,len(feature)-1):
    plt.subplot(6, 3,i)
    plt.title(feature[i])
    plt.boxplot(train[feature[i]])

plt.show()
```

![](D:\pebble-jji-github-blog\download-16485643264292.png)

#### Winsorizing

윈저라이징 함수를 만들어서 상하위 5%의 값으로 이상치를 대체한다. 윈저라이징 시 범주형 변수는 처리되지 않으므로 제외하고 표준화 후 다시 결합한다.

```python
def winsor(df) :
  features = df 
  for colname in df.columns :
    for i in range(len(df[colname])) : 
      if df[colname][i] > float(df[colname].quantile(0.95,interpolation='nearest')) :
        df[colname][i] = float(df[colname].quantile(0.95,interpolation='nearest'))
      elif df[colname][i] < float(df[colname].quantile(0.05,interpolation='nearest')) :
        df[colname][i] = float(df[colname].quantile(0.05,interpolation='nearest'))
      else : 
        continue
```

```python
train = train.drop('Gender',axis = 1)
winsor(train)
```

이상치가 잘 없어졌는지 boxplot을 그려보자.

```python
feature = train.columns

plt.figure(figsize=(20,60))

for i in range(1,len(feature)-1):
    plt.subplot(6, 3,i)
    plt.title(feature[i])
    plt.boxplot(train[feature[i]])

plt.show()
```

![](D:\pebble-jji-github-blog\download-16485642845121.png)

특이값이 잘 제거된 것을 볼 수 있다.

#### 스케일링  : 표준화

```python
from sklearn.preprocessing import StandardScaler

feature = train.columns

ss = StandardScaler()

ss.fit(train.drop('Target', axis = 1))

train_scaled = ss.transform(train.drop('Target', axis = 1))

train_scaled = pd.DataFrame(train_scaled, columns=feature[:-1])

ssf = StandardScaler()

ssf.fit(test)

test_scaled = ssf.transform(test)

test_scaled = pd.DataFrame(test_scaled, columns=test.columns)
```

성별과  타겟값을 다시 붙인다.

```
train_scaled.loc[:,'Gender'] = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.zip (Unzipped Files)/data/train.csv')['Gender']
train_scaled.loc[:,'Target'] = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.zip (Unzipped Files)/data/train.csv')['Target']
test_scaled.loc[:,'Gender'] = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.zip (Unzipped Files)/data/test.csv')['Gender']
```

```python
train_scaled.head()
```

|      |  Lenght   | Diameter  |  Height   | Whole Weight | Shucked Weight | Viscra Weight | Shell Weight | Gender | Target |
| :--: | :-------: | :-------: | :-------: | :----------: | :------------: | :-----------: | :----------: | :----: | :----: |
|  0   | 0.726598  | 0.668253  | -0.682843 |   0.629557   |    0.198207    |   1.092852    |   0.567558   |   M    |   15   |
|  1   | -0.848302 | -0.998646 | -1.239785 |  -0.950696   |   -0.874334    |   -0.955878   |  -1.015395   |   I    |   8    |
|  2   | 0.501612  | 0.883337  | 1.544925  |   1.064341   |    0.878716    |   0.733596    |   1.337852   |   I    |   18   |
|  3   | 0.096638  | -0.030769 | 0.987983  |   0.965576   |    0.965013    |   1.437543    |   0.775538   |   M    |   13   |
|  4   | -1.928234 | -1.858982 | -1.379021 |  -1.484246   |   -1.458684    |   -1.431650   |  -1.512235   |   I    |   6    |

```python
test_scaled.head()
```

|      |  Lenght   | Diameter  |  Height   | Whole Weight | Shucked Weight | Viscra Weight | Shell Weight | Gender |
| :--: | :-------: | :-------: | :-------: | :----------: | :------------: | :-----------: | :----------: | :----: |
|  0   | 0.587573  | 0.623431  | 0.360638  |   0.603526   |    0.416165    |   -0.022254   |  -0.604782   |   F    |
|  1   | 0.462605  | 0.421430  | 0.244272  |   0.204345   |   -0.378606    |   0.009973    |   0.883631   |   M    |
|  2   | -2.203383 | -2.053089 | -1.617578 |  -1.503490   |   -1.440564    |   -1.486282   |  -1.508721   |   I    |
|  3   | 0.545917  | 0.522430  | -0.221190 |   0.564431   |    0.432015    |   0.230958    |   0.665814   |   M    |
|  4   | 0.587573  | 0.572931  | 0.011541  |   0.587065   |    0.715053    |   0.585456    |   0.484301   |   F    |

내일 본격적으로 모델을 적용해보자.
