---
layout : single
title : "3/15 (화) ML day 1" 
---

## Chapter 01 나의 첫 머신러닝

### 1 | 인공지능과 머신러닝, 딥러닝

인공지능 : 사람처럼 학습하고 추론할 수 있는 지능을 가진 컴퓨터 시스템을 만드는 기술

* 머신러닝 : 데이터에서 규칙을 찾아 학습하는 알고리즘을 연구하는 분야  
by 사이킷런
  - 딥러닝 : 인공신경망을 기반으로 머신러닝 기술 들 중 하나  
  by 텐서플로우, 파이토치

### 2 | 코랩과 주피터 노트북 (생략)
### 3 | 마켓과 머신러닝

#### 생선 분류 모델 (feat. k-최근접 이웃 알고리즘)

일단은 도미와 빙어부터 구분해보자.  

##### 데이터 구성하기

- 도미 데이터는 어떻게 생겼나  

```
# 도미 길이
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 
                31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 
                35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]

# 도미 무게
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 
                500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 
                700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0]

import matplotlib.pyplot as plt

plt.scatter(bream_length,bream_weight)

plt.title('Bream')

plt.xlabel('length')
plt.ylabel('weight')

plt.show()
```

- 빙어 데이터는 어떻게 생겼나  


```
# 빙어 길이
smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0]

# 빙어 무게
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]

plt.scatter(smelt_length,smelt_weight)

plt.title('Smelt')

plt.xlabel('length')
plt.ylabel('weight')

plt.show()
```

- 두 데이터를 한 눈에 보자.  


```
plt.scatter(bream_length,bream_weight,color = 'Red',label = 'Bream')
plt.scatter(smelt_length,smelt_weight,color = 'Blue', label = 'Smelt')
plt.legend()

plt.title('Fish')

plt.xlabel('length')
plt.ylabel('weight')

plt.show()
```


- 두 데이터를 합치자.  

```
# 도미 + 빙어 = 전체 리스트
length = bream_length + smelt_length
weight = bream_weight + smelt_weight

# Comprehension으로 각 물고기의 길이와 무게 대응시키기
fish_data = [[l,w] for l, w in zip(length,weight)]
```

##### k-Nearest Neighbors

생선이 도미와 빙어 중 무엇인지 알려면 도미인지 아닌지 알려는 줘야지  
얘는 답지보고 공부하는 애라서 답 줘야한다고.

도미를 찾을거니까 도미는 1로, 빙어는 0으로!


```
fish_target = [1] * 35 + [0] * 14
```


이제 데이터도 있고 답지도 있으니까 **k-최근접 이웃 알고리즘** 을 쓸 수 있다.
사이킷런에서 해당 알고리즘을 불러오자.  


```
from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier() # KN 뭐시기 객체 가져오라

kn.fit(fish_data,fish_target) # 대충 KN 뭐시기로 알고리즘을 훈련시켜서 도미를 찾아내라는 뜻.

print(kn.score(fish_data,fish_target))
```


score 함수를 썼을 때 1이 나오는 이유는 뭘까.

_kn.score(fish_data,fish_target)_ 은 fish data가 도미인지 빙어인지 물어보고 점수를 매겼는데 다 맞췄다는 거다.


```
plt.scatter(bream_length,bream_weight,color = 'Red',label = 'Bream')
plt.scatter(smelt_length,smelt_weight,color = 'Blue', label = 'Smelt')
plt.scatter(40,900,color = 'green',marker = '^')

plt.legend()

plt.title('Fish')

plt.xlabel('length')
plt.ylabel('weight')

plt.show()
```

0이라고 했으니까 50cm, 100g인 생선은 빙어일 것임

```
print(kn._fit_X)

print(kn._y)
```

그대로다. 뭐 딱히 훈련한건 없나보다.

```
kn49 = KNeighborsClassifier(n_neighbors = 49) # 가까운 49개를 참고해서 물고기의 정체를 밝힌다는 뜻

kn49.fit(fish_data,fish_target)

kn49.score(fish_data,fish_target)
```

가장 가까운 데이터 49개를 사용하는 모델을 적용하면 도미가 훨씬 많아서 무조건 도미라고 할 것이다.  

그럼 나머지 14개의 도미는 틀리겠지. 그러니까 확률은

```
len(bream_length) / len(fish_data)
```

위와 같이 정확도와 같은 것을 볼 수 있다.