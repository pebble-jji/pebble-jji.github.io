---
layout : single
title : "3/25(금) ~ 3/26(토) ML day 9 ~ 10" 
---

## 핸즈온 머신러닝 

### Chapter 2 | 머신러닝 프로젝트 처음부터 끝까지

#### 파이프라인

문제를 해결하기 위한 프로세스를 도식화하는 거라고 생각하면 될 것 같다.

#### 성능 지표

1. 평균제곱근오차 RMSE (Root Mean Square Error)  
$$ RMSE(X,h) =\sqrt \frac{\Sigma_{i=1}^m (h(X^{(i)}) - y^{(i)} )^2}{m} $$  
- $ m $ : 샘플 개수  
- $ X^{(i)} $ : $i$번째 샘플의 전체 특성값의 벡터  
- $y^{(i)}$ : $i$번째 샘플의 레이블값  
- $h(X^{(i)}) = \hat{y}^{(i)}$ : $i$번째 샘플의 예측값, 가설에 특성값을 적용한 값  
- MAE보다 이상치에 더 민감



2. 평균절대오차 MAE (Mean Absolute Error)  
$$ MAE(X,h) = \lvert \frac{\Sigma_{i=1}^m (h(X^{(i)}) - y^{(i)} )^2}{m} \rvert $$  

RMSE와 MAE 모두 예측값의 벡터와 타깃값의 벡터 사이의 거리를 재는 방법  

#### 데이터 불러오기
```
import os # 운영체제와 상호작용하는 라이브러리
import tarfile # tar 계열의 압축 파일을 다루는 라이브러리
import urllib # url을 다루는 라이브러리

DOWNLOAD_ROOT = 'https://raw.githubusercontent.com/ageron/handson-ml2/master/' # 파일이 있는 URL
HOUSING_PATH = os.path.join('datasets','housing') # path로써 븥여라.
HOUSING_URL = DOWNLOAD_ROOT + 'datasets/housing/housing.tgz' # 파일이 있는 위치

def fetch_housing_data(housing_url = HOUSING_URL, housing_path = HOUSING_PATH) :
    os.makedirs(housing_path, exist_ok = True) # 폴더 만들어줌
    tgz_path = os.path.join(housing_path, 'housing.tgz')
    urllib.request.urlretrieve(housing_url, tgz_path)
    housing_tgz = tarfile.open(tgz_path) # 압축파일 열기
    housing_tgz.extractall(path = housing_path) # 압축 풀기
    housing_tgz.close()
    
fetch_housing_data()

import pandas as pd

def load_housing_data(housing_path = HOUSING_PATH) :
    csv_path = os.path.join(housing_path,'housing.csv') # csv로 만들기
    return pd.read_csv(csv_path)

housing = load_housing_data()
```

파일을 housing 변수에 불러왔다.  

#### EDA

```
housing.info()
```
![](D:\pebble-jji-github-blog\KakaoTalk_20220327_021657268.png)

total_bedrooms에 207개의 결측치가 있다.  

```
housing.describe()
```

![](D:\pebble-jji-github-blog\KakaoTalk_20220327_021641348.png)

![](D:\pebble-jji-github-blog\다운로드.png)

ocean_proximity는 범주형 변수라서 describe에서 안 나오니 따로 세주자.  

```
housing['ocean_proximity'].value_counts()
```

![](D:\pebble-jji-github-blog\KakaoTalk_20220327_021712165.png)

레이블이 4개이다.

#### 훈련 세트와 테스트 세트 만들기

```
import numpy as np

def split_train_test(data,test_ratio):
    shuffled_indices = np.random.permutation(len(data)) # 인덱스 섞어주기
    test_size = int(len(data) * test_ratio) # 테스트 세트 사이즈 정하기
    test_indices = shuffled_indices[:test_size] # 테스트 인덱스
    train_indices = shuffled_indices[test_size:] # 훈련 인덱스
    return data.iloc[train_indices], data.iloc[test_indices] # 모든 열 출력


train_set, test_set = split_train_test(housing,0.2)
```

근데 이거 인덱스가 랜덤이라 껐다 켜면 다 다시 뽑아버린다...  
시드를 지정하면 되긴 하지만 그럼 업데이트한게 반영이 안돼버리자너...  
그러니까 얘를 좀 합리적으로 고정하자는 의미.  

1. 각 샘플마다 고유 번호를 매긴다
2. 해시값이 test size 보다 작은가 본다.
3. 테스트 세트로 보내든가 말든가 한다.

```
from zlib import crc32
def test_set_check(identifier, test_ratio) :
    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * (2 ** 32)

def split_train_test_by_id(data,test_ratio,id_column) : 
    ids = data[id_column]
    in_test_set = ids.apply(lambda id_:test_set_check(id_,test_ratio))
    return data.loc[~in_test_set] , data.loc[in_test_set]

housing_with_id = housing.reset_index()

train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, 'index')

housing_with_id['id'] = housing['longitude'] * 1000 + housing['latitude']

train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, 'id')
```